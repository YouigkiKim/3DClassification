2024-10-16 22:19:31,468   INFO  **********************Start logging**********************
2024-10-16 22:19:31,468   INFO  CUDA_VISIBLE_DEVICES=2,3
2024-10-16 22:19:31,468   INFO  Training in distributed mode : total_batch_size: 4
2024-10-16 22:19:31,468   INFO  cfg_file         cfgs/waymo_models/dsvt_voxel_whole.yaml
2024-10-16 22:19:31,468   INFO  batch_size       2
2024-10-16 22:19:31,468   INFO  epochs           30
2024-10-16 22:19:31,469   INFO  workers          4
2024-10-16 22:19:31,469   INFO  extra_tag        default
2024-10-16 22:19:31,469   INFO  ckpt             None
2024-10-16 22:19:31,469   INFO  pretrained_model None
2024-10-16 22:19:31,469   INFO  launcher         pytorch
2024-10-16 22:19:31,469   INFO  tcp_port         18888
2024-10-16 22:19:31,469   INFO  sync_bn          False
2024-10-16 22:19:31,469   INFO  fix_random_seed  False
2024-10-16 22:19:31,469   INFO  ckpt_save_interval 1
2024-10-16 22:19:31,469   INFO  local_rank       0
2024-10-16 22:19:31,469   INFO  max_ckpt_save_num 30
2024-10-16 22:19:31,469   INFO  merge_all_iters_to_one_epoch False
2024-10-16 22:19:31,469   INFO  set_cfgs         None
2024-10-16 22:19:31,469   INFO  max_waiting_mins 0
2024-10-16 22:19:31,469   INFO  start_epoch      0
2024-10-16 22:19:31,470   INFO  num_epochs_to_eval 0
2024-10-16 22:19:31,470   INFO  save_to_file     False
2024-10-16 22:19:31,470   INFO  use_tqdm_to_record False
2024-10-16 22:19:31,470   INFO  logger_iter_interval 50
2024-10-16 22:19:31,470   INFO  ckpt_save_time_interval 300
2024-10-16 22:19:31,470   INFO  wo_gpu_stat      False
2024-10-16 22:19:31,470   INFO  use_amp          False
2024-10-16 22:19:31,470   INFO  cfg.ROOT_DIR: /home/ailab/git/Team_3/baseline_code_and_model/03_3D객체검출차량용/02_baseline_code_and_model
2024-10-16 22:19:31,470   INFO  cfg.LOCAL_RANK: 0
2024-10-16 22:19:31,470   INFO  cfg.CLASS_NAMES: ['Vehicle', 'Pedestrian', 'Cyclist']
2024-10-16 22:19:31,470   INFO  ----------- DATA_CONFIG -----------
2024-10-16 22:19:31,470   INFO  cfg.DATA_CONFIG.DATASET: CustomAvDataset
2024-10-16 22:19:31,470   INFO  cfg.DATA_CONFIG.DATA_PATH: /home/ailab/AILabDataset/01_Open_Dataset/39_AutoDna/3d_object_detection/3d_mod_av_db
2024-10-16 22:19:31,470   INFO  cfg.DATA_CONFIG.POINT_CLOUD_RANGE: [-70.0, -70.0, -4.0, 70.0, 70.0, 4.0]
2024-10-16 22:19:31,470   INFO  ----------- MAP_CLASS_TO_KITTI -----------
2024-10-16 22:19:31,471   INFO  cfg.DATA_CONFIG.MAP_CLASS_TO_KITTI.Vehicle: Car
2024-10-16 22:19:31,471   INFO  cfg.DATA_CONFIG.MAP_CLASS_TO_KITTI.Pedestrian: Pedestrian
2024-10-16 22:19:31,471   INFO  cfg.DATA_CONFIG.MAP_CLASS_TO_KITTI.Cyclist: Cyclist
2024-10-16 22:19:31,471   INFO  ----------- DATA_SPLIT -----------
2024-10-16 22:19:31,471   INFO  cfg.DATA_CONFIG.DATA_SPLIT.train: train_origin2
2024-10-16 22:19:31,471   INFO  cfg.DATA_CONFIG.DATA_SPLIT.test: val_origin2
2024-10-16 22:19:31,471   INFO  ----------- INFO_PATH -----------
2024-10-16 22:19:31,471   INFO  cfg.DATA_CONFIG.INFO_PATH.train: ['Team_3_whole_infos_train_origin2.pkl']
2024-10-16 22:19:31,471   INFO  cfg.DATA_CONFIG.INFO_PATH.test: ['Team_3_whole_infos_val_origin2.pkl']
2024-10-16 22:19:31,471   INFO  ----------- POINT_FEATURE_ENCODING -----------
2024-10-16 22:19:31,471   INFO  cfg.DATA_CONFIG.POINT_FEATURE_ENCODING.encoding_type: absolute_coordinates_encoding
2024-10-16 22:19:31,471   INFO  cfg.DATA_CONFIG.POINT_FEATURE_ENCODING.used_feature_list: ['x', 'y', 'z']
2024-10-16 22:19:31,471   INFO  cfg.DATA_CONFIG.POINT_FEATURE_ENCODING.src_feature_list: ['x', 'y', 'z', 'intensity']
2024-10-16 22:19:31,471   INFO  ----------- DATA_AUGMENTOR -----------
2024-10-16 22:19:31,471   INFO  cfg.DATA_CONFIG.DATA_AUGMENTOR.DISABLE_AUG_LIST: ['placeholder']
2024-10-16 22:19:31,471   INFO  cfg.DATA_CONFIG.DATA_AUGMENTOR.AUG_CONFIG_LIST: [{'NAME': 'gt_sampling', 'USE_ROAD_PLANE': False, 'DB_INFO_PATH': ['Team_3_custom_av_dbinfos_train.pkl'], 'PREPARE': {'filter_by_min_points': ['Car:5', 'Pedestrian:5', 'Cyclist:5']}, 'SAMPLE_GROUPS': ['Vehicle:15', 'Pedestrian:10', 'Cyclist:10'], 'NUM_POINT_FEATURES': 4, 'DATABASE_WITH_FAKELIDAR': False, 'REMOVE_EXTRA_WIDTH': [0.0, 0.0, 0.0], 'LIMIT_WHOLE_SCENE': True}, {'NAME': 'random_world_flip', 'ALONG_AXIS_LIST': ['x', 'y']}, {'NAME': 'random_world_rotation', 'WORLD_ROT_ANGLE': [-0.78539816, 0.78539816]}, {'NAME': 'random_world_scaling', 'WORLD_SCALE_RANGE': [0.95, 1.05]}, {'NAME': 'random_world_translation', 'NOISE_TRANSLATE_STD': [0.5, 0.5, 0.5]}]
2024-10-16 22:19:31,471   INFO  cfg.DATA_CONFIG.DATA_PROCESSOR: [{'NAME': 'mask_points_and_boxes_outside_range', 'REMOVE_OUTSIDE_BOXES': True}, {'NAME': 'shuffle_points', 'SHUFFLE_ENABLED': {'train': True, 'test': False}}, {'NAME': 'transform_points_to_voxels_placeholder', 'VOXEL_SIZE': [0.25, 0.25, 0.25]}]
2024-10-16 22:19:31,471   INFO  cfg.DATA_CONFIG._BASE_CONFIG_: cfgs/dataset_configs/custom_av_dataset_whole.yaml
2024-10-16 22:19:31,471   INFO  ----------- MODEL -----------
2024-10-16 22:19:31,471   INFO  cfg.MODEL.NAME: CenterPoint
2024-10-16 22:19:31,471   INFO  ----------- VFE -----------
2024-10-16 22:19:31,472   INFO  cfg.MODEL.VFE.NAME: DynamicVoxelVFE
2024-10-16 22:19:31,472   INFO  cfg.MODEL.VFE.WITH_DISTANCE: False
2024-10-16 22:19:31,472   INFO  cfg.MODEL.VFE.USE_ABSLOTE_XYZ: True
2024-10-16 22:19:31,472   INFO  cfg.MODEL.VFE.USE_NORM: True
2024-10-16 22:19:31,472   INFO  cfg.MODEL.VFE.NUM_FILTERS: [192, 192]
2024-10-16 22:19:31,472   INFO  ----------- BACKBONE_3D -----------
2024-10-16 22:19:31,472   INFO  cfg.MODEL.BACKBONE_3D.NAME: DSVT
2024-10-16 22:19:31,472   INFO  ----------- INPUT_LAYER -----------
2024-10-16 22:19:31,472   INFO  cfg.MODEL.BACKBONE_3D.INPUT_LAYER.sparse_shape: [560, 560, 32]
2024-10-16 22:19:31,472   INFO  cfg.MODEL.BACKBONE_3D.INPUT_LAYER.downsample_stride: [[1, 1, 4], [1, 1, 4], [1, 1, 2]]
2024-10-16 22:19:31,472   INFO  cfg.MODEL.BACKBONE_3D.INPUT_LAYER.d_model: [192, 192, 192, 192]
2024-10-16 22:19:31,472   INFO  cfg.MODEL.BACKBONE_3D.INPUT_LAYER.set_info: [[48, 1], [48, 1], [48, 1], [48, 1]]
2024-10-16 22:19:31,472   INFO  cfg.MODEL.BACKBONE_3D.INPUT_LAYER.window_shape: [[12, 12, 32], [12, 12, 8], [12, 12, 2], [12, 12, 1]]
2024-10-16 22:19:31,472   INFO  cfg.MODEL.BACKBONE_3D.INPUT_LAYER.hybrid_factor: [2, 2, 1]
2024-10-16 22:19:31,472   INFO  cfg.MODEL.BACKBONE_3D.INPUT_LAYER.shifts_list: [[[0, 0, 0], [6, 6, 0]], [[0, 0, 0], [6, 6, 0]], [[0, 0, 0], [6, 6, 0]], [[0, 0, 0], [6, 6, 0]]]
2024-10-16 22:19:31,472   INFO  cfg.MODEL.BACKBONE_3D.INPUT_LAYER.normalize_pos: False
2024-10-16 22:19:31,472   INFO  cfg.MODEL.BACKBONE_3D.block_name: ['DSVTBlock', 'DSVTBlock', 'DSVTBlock', 'DSVTBlock']
2024-10-16 22:19:31,472   INFO  cfg.MODEL.BACKBONE_3D.set_info: [[48, 1], [48, 1], [48, 1], [48, 1]]
2024-10-16 22:19:31,472   INFO  cfg.MODEL.BACKBONE_3D.d_model: [192, 192, 192, 192]
2024-10-16 22:19:31,472   INFO  cfg.MODEL.BACKBONE_3D.nhead: [8, 8, 8, 8]
2024-10-16 22:19:31,472   INFO  cfg.MODEL.BACKBONE_3D.dim_feedforward: [384, 384, 384, 384]
2024-10-16 22:19:31,472   INFO  cfg.MODEL.BACKBONE_3D.dropout: 0.0
2024-10-16 22:19:31,473   INFO  cfg.MODEL.BACKBONE_3D.activation: gelu
2024-10-16 22:19:31,473   INFO  cfg.MODEL.BACKBONE_3D.reduction_type: attention
2024-10-16 22:19:31,473   INFO  cfg.MODEL.BACKBONE_3D.output_shape: [280, 280]
2024-10-16 22:19:31,473   INFO  cfg.MODEL.BACKBONE_3D.conv_out_channel: 192
2024-10-16 22:19:31,473   INFO  cfg.MODEL.BACKBONE_3D.USE_CHECKPOINT: True
2024-10-16 22:19:31,473   INFO  ----------- MAP_TO_BEV -----------
2024-10-16 22:19:31,473   INFO  cfg.MODEL.MAP_TO_BEV.NAME: PointPillarScatter3d
2024-10-16 22:19:31,473   INFO  cfg.MODEL.MAP_TO_BEV.INPUT_SHAPE: [560, 560, 1]
2024-10-16 22:19:31,473   INFO  cfg.MODEL.MAP_TO_BEV.NUM_BEV_FEATURES: 192
2024-10-16 22:19:31,473   INFO  ----------- BACKBONE_2D -----------
2024-10-16 22:19:31,473   INFO  cfg.MODEL.BACKBONE_2D.NAME: BaseBEVResBackbone
2024-10-16 22:19:31,473   INFO  cfg.MODEL.BACKBONE_2D.LAYER_NUMS: [1, 2, 2]
2024-10-16 22:19:31,473   INFO  cfg.MODEL.BACKBONE_2D.LAYER_STRIDES: [1, 2, 2]
2024-10-16 22:19:31,473   INFO  cfg.MODEL.BACKBONE_2D.NUM_FILTERS: [128, 128, 256]
2024-10-16 22:19:31,473   INFO  cfg.MODEL.BACKBONE_2D.UPSAMPLE_STRIDES: [1, 2, 4]
2024-10-16 22:19:31,473   INFO  cfg.MODEL.BACKBONE_2D.NUM_UPSAMPLE_FILTERS: [128, 128, 128]
2024-10-16 22:19:31,473   INFO  ----------- DENSE_HEAD -----------
2024-10-16 22:19:31,473   INFO  cfg.MODEL.DENSE_HEAD.NAME: CenterHead
2024-10-16 22:19:31,473   INFO  cfg.MODEL.DENSE_HEAD.CLASS_AGNOSTIC: False
2024-10-16 22:19:31,473   INFO  cfg.MODEL.DENSE_HEAD.CLASS_NAMES_EACH_HEAD: [['Vehicle', 'Pedestrian', 'Cyclist']]
2024-10-16 22:19:31,473   INFO  cfg.MODEL.DENSE_HEAD.SHARED_CONV_CHANNEL: 64
2024-10-16 22:19:31,473   INFO  cfg.MODEL.DENSE_HEAD.USE_BIAS_BEFORE_NORM: False
2024-10-16 22:19:31,473   INFO  cfg.MODEL.DENSE_HEAD.NUM_HM_CONV: 2
2024-10-16 22:19:31,474   INFO  cfg.MODEL.DENSE_HEAD.BN_EPS: 0.001
2024-10-16 22:19:31,474   INFO  cfg.MODEL.DENSE_HEAD.BN_MOM: 0.01
2024-10-16 22:19:31,474   INFO  ----------- SEPARATE_HEAD_CFG -----------
2024-10-16 22:19:31,474   INFO  cfg.MODEL.DENSE_HEAD.SEPARATE_HEAD_CFG.HEAD_ORDER: ['center', 'center_z', 'dim', 'rot']
2024-10-16 22:19:31,474   INFO  ----------- HEAD_DICT -----------
2024-10-16 22:19:31,474   INFO  ----------- center -----------
2024-10-16 22:19:31,474   INFO  cfg.MODEL.DENSE_HEAD.SEPARATE_HEAD_CFG.HEAD_DICT.center.out_channels: 2
2024-10-16 22:19:31,474   INFO  cfg.MODEL.DENSE_HEAD.SEPARATE_HEAD_CFG.HEAD_DICT.center.num_conv: 2
2024-10-16 22:19:31,474   INFO  ----------- center_z -----------
2024-10-16 22:19:31,474   INFO  cfg.MODEL.DENSE_HEAD.SEPARATE_HEAD_CFG.HEAD_DICT.center_z.out_channels: 1
2024-10-16 22:19:31,474   INFO  cfg.MODEL.DENSE_HEAD.SEPARATE_HEAD_CFG.HEAD_DICT.center_z.num_conv: 2
2024-10-16 22:19:31,474   INFO  ----------- dim -----------
2024-10-16 22:19:31,474   INFO  cfg.MODEL.DENSE_HEAD.SEPARATE_HEAD_CFG.HEAD_DICT.dim.out_channels: 3
2024-10-16 22:19:31,474   INFO  cfg.MODEL.DENSE_HEAD.SEPARATE_HEAD_CFG.HEAD_DICT.dim.num_conv: 2
2024-10-16 22:19:31,474   INFO  ----------- rot -----------
2024-10-16 22:19:31,474   INFO  cfg.MODEL.DENSE_HEAD.SEPARATE_HEAD_CFG.HEAD_DICT.rot.out_channels: 2
2024-10-16 22:19:31,474   INFO  cfg.MODEL.DENSE_HEAD.SEPARATE_HEAD_CFG.HEAD_DICT.rot.num_conv: 2
2024-10-16 22:19:31,474   INFO  ----------- iou -----------
2024-10-16 22:19:31,474   INFO  cfg.MODEL.DENSE_HEAD.SEPARATE_HEAD_CFG.HEAD_DICT.iou.out_channels: 1
2024-10-16 22:19:31,474   INFO  cfg.MODEL.DENSE_HEAD.SEPARATE_HEAD_CFG.HEAD_DICT.iou.num_conv: 2
2024-10-16 22:19:31,474   INFO  ----------- TARGET_ASSIGNER_CONFIG -----------
2024-10-16 22:19:31,474   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.FEATURE_MAP_STRIDE: 1
2024-10-16 22:19:31,474   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.NUM_MAX_OBJS: 500
2024-10-16 22:19:31,475   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.GAUSSIAN_OVERLAP: 0.1
2024-10-16 22:19:31,475   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.MIN_RADIUS: 2
2024-10-16 22:19:31,475   INFO  cfg.MODEL.DENSE_HEAD.IOU_REG_LOSS: True
2024-10-16 22:19:31,475   INFO  ----------- LOSS_CONFIG -----------
2024-10-16 22:19:31,475   INFO  ----------- LOSS_WEIGHTS -----------
2024-10-16 22:19:31,475   INFO  cfg.MODEL.DENSE_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.cls_weight: 1.0
2024-10-16 22:19:31,475   INFO  cfg.MODEL.DENSE_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.loc_weight: 2.0
2024-10-16 22:19:31,475   INFO  cfg.MODEL.DENSE_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.code_weights: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
2024-10-16 22:19:31,475   INFO  ----------- POST_PROCESSING -----------
2024-10-16 22:19:31,475   INFO  cfg.MODEL.DENSE_HEAD.POST_PROCESSING.SCORE_THRESH: 0.1
2024-10-16 22:19:31,475   INFO  cfg.MODEL.DENSE_HEAD.POST_PROCESSING.POST_CENTER_LIMIT_RANGE: [-80, -80, -10.0, 80, 80, 10.0]
2024-10-16 22:19:31,475   INFO  cfg.MODEL.DENSE_HEAD.POST_PROCESSING.MAX_OBJ_PER_SAMPLE: 500
2024-10-16 22:19:31,475   INFO  cfg.MODEL.DENSE_HEAD.POST_PROCESSING.USE_IOU_TO_RECTIFY_SCORE: True
2024-10-16 22:19:31,475   INFO  cfg.MODEL.DENSE_HEAD.POST_PROCESSING.IOU_RECTIFIER: [0.68, 0.71, 0.65]
2024-10-16 22:19:31,475   INFO  ----------- NMS_CONFIG -----------
2024-10-16 22:19:31,475   INFO  cfg.MODEL.DENSE_HEAD.POST_PROCESSING.NMS_CONFIG.NMS_TYPE: class_specific_nms
2024-10-16 22:19:31,475   INFO  cfg.MODEL.DENSE_HEAD.POST_PROCESSING.NMS_CONFIG.NMS_THRESH: [0.75, 0.6, 0.55]
2024-10-16 22:19:31,475   INFO  cfg.MODEL.DENSE_HEAD.POST_PROCESSING.NMS_CONFIG.NMS_PRE_MAXSIZE: [4096, 4096, 4096]
2024-10-16 22:19:31,475   INFO  cfg.MODEL.DENSE_HEAD.POST_PROCESSING.NMS_CONFIG.NMS_POST_MAXSIZE: [500, 500, 500]
2024-10-16 22:19:31,475   INFO  ----------- POST_PROCESSING -----------
2024-10-16 22:19:31,475   INFO  cfg.MODEL.POST_PROCESSING.RECALL_THRESH_LIST: [0.3, 0.5, 0.7]
2024-10-16 22:19:31,475   INFO  cfg.MODEL.POST_PROCESSING.EVAL_METRIC: waymo
2024-10-16 22:19:31,475   INFO  ----------- OPTIMIZATION -----------
2024-10-16 22:19:31,476   INFO  cfg.OPTIMIZATION.BATCH_SIZE_PER_GPU: 2
2024-10-16 22:19:31,476   INFO  cfg.OPTIMIZATION.NUM_EPOCHS: 30
2024-10-16 22:19:31,476   INFO  cfg.OPTIMIZATION.OPTIMIZER: adam_onecycle
2024-10-16 22:19:31,476   INFO  cfg.OPTIMIZATION.LR: 0.003
2024-10-16 22:19:31,476   INFO  cfg.OPTIMIZATION.WEIGHT_DECAY: 0.05
2024-10-16 22:19:31,476   INFO  cfg.OPTIMIZATION.MOMENTUM: 0.9
2024-10-16 22:19:31,476   INFO  cfg.OPTIMIZATION.MOMS: [0.95, 0.85]
2024-10-16 22:19:31,476   INFO  cfg.OPTIMIZATION.PCT_START: 0.1
2024-10-16 22:19:31,476   INFO  cfg.OPTIMIZATION.DIV_FACTOR: 100
2024-10-16 22:19:31,476   INFO  cfg.OPTIMIZATION.DECAY_STEP_LIST: [35, 45]
2024-10-16 22:19:31,476   INFO  cfg.OPTIMIZATION.LR_DECAY: 0.1
2024-10-16 22:19:31,476   INFO  cfg.OPTIMIZATION.LR_CLIP: 1e-07
2024-10-16 22:19:31,476   INFO  cfg.OPTIMIZATION.LR_WARMUP: False
2024-10-16 22:19:31,476   INFO  cfg.OPTIMIZATION.WARMUP_EPOCH: 1
2024-10-16 22:19:31,476   INFO  cfg.OPTIMIZATION.GRAD_NORM_CLIP: 10
2024-10-16 22:19:31,476   INFO  cfg.OPTIMIZATION.LOSS_SCALE_FP16: 32.0
2024-10-16 22:19:31,476   INFO  ----------- HOOK -----------
2024-10-16 22:19:31,476   INFO  ----------- DisableAugmentationHook -----------
2024-10-16 22:19:31,476   INFO  cfg.HOOK.DisableAugmentationHook.DISABLE_AUG_LIST: ['gt_sampling', 'random_world_flip', 'random_world_rotation', 'random_world_scaling', 'random_world_translation']
2024-10-16 22:19:31,476   INFO  cfg.HOOK.DisableAugmentationHook.NUM_LAST_EPOCHS: 1
2024-10-16 22:19:31,476   INFO  cfg.TAG: dsvt_voxel_whole
2024-10-16 22:19:31,477   INFO  cfg.EXP_GROUP_PATH: waymo_models
2024-10-16 22:19:31,521   INFO  ----------- Create dataloader & network & optimizer -----------
2024-10-16 22:19:31,921   INFO  Database filter by min points Pedestrian: 46175 => 45511
2024-10-16 22:19:31,922   INFO  Database filter by min points Cyclist: 3054 => 3018
2024-10-16 22:19:31,926   INFO  Loading Custom AV dataset.
2024-10-16 22:19:32,041   INFO  Total samples for Custom AV dataset: 13739
2024-10-16 22:19:35,332   INFO  ----------- Model CenterPoint created, param count: 9101996 -----------
2024-10-16 22:19:35,332   INFO  DistributedDataParallel(
  (module): CenterPoint(
    (vfe): DynamicVoxelVFE(
      (pfn_layers): ModuleList(
        (0): PFNLayerV2(
          (linear): Linear(in_features=9, out_features=96, bias=False)
          (norm): BatchNorm1d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (1): PFNLayerV2(
          (linear): Linear(in_features=192, out_features=192, bias=False)
          (norm): BatchNorm1d(192, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
      )
    )
    (backbone_3d): DSVT(
      (input_layer): DSVTInputLayer(
        (posembed_layers): ModuleList(
          (0): ModuleList(
            (0): ModuleList(
              (0): PositionEmbeddingLearned(
                (position_embedding_head): Sequential(
                  (0): Linear(in_features=3, out_features=192, bias=True)
                  (1): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (2): ReLU(inplace=True)
                  (3): Linear(in_features=192, out_features=192, bias=True)
                )
              )
              (1): PositionEmbeddingLearned(
                (position_embedding_head): Sequential(
                  (0): Linear(in_features=3, out_features=192, bias=True)
                  (1): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (2): ReLU(inplace=True)
                  (3): Linear(in_features=192, out_features=192, bias=True)
                )
              )
            )
          )
          (1): ModuleList(
            (0): ModuleList(
              (0): PositionEmbeddingLearned(
                (position_embedding_head): Sequential(
                  (0): Linear(in_features=3, out_features=192, bias=True)
                  (1): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (2): ReLU(inplace=True)
                  (3): Linear(in_features=192, out_features=192, bias=True)
                )
              )
              (1): PositionEmbeddingLearned(
                (position_embedding_head): Sequential(
                  (0): Linear(in_features=3, out_features=192, bias=True)
                  (1): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (2): ReLU(inplace=True)
                  (3): Linear(in_features=192, out_features=192, bias=True)
                )
              )
            )
          )
          (2): ModuleList(
            (0): ModuleList(
              (0): PositionEmbeddingLearned(
                (position_embedding_head): Sequential(
                  (0): Linear(in_features=3, out_features=192, bias=True)
                  (1): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (2): ReLU(inplace=True)
                  (3): Linear(in_features=192, out_features=192, bias=True)
                )
              )
              (1): PositionEmbeddingLearned(
                (position_embedding_head): Sequential(
                  (0): Linear(in_features=3, out_features=192, bias=True)
                  (1): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (2): ReLU(inplace=True)
                  (3): Linear(in_features=192, out_features=192, bias=True)
                )
              )
            )
          )
          (3): ModuleList(
            (0): ModuleList(
              (0): PositionEmbeddingLearned(
                (position_embedding_head): Sequential(
                  (0): Linear(in_features=2, out_features=192, bias=True)
                  (1): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (2): ReLU(inplace=True)
                  (3): Linear(in_features=192, out_features=192, bias=True)
                )
              )
              (1): PositionEmbeddingLearned(
                (position_embedding_head): Sequential(
                  (0): Linear(in_features=2, out_features=192, bias=True)
                  (1): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (2): ReLU(inplace=True)
                  (3): Linear(in_features=192, out_features=192, bias=True)
                )
              )
            )
          )
        )
      )
      (stage_0): ModuleList(
        (0): DSVTBlock(
          (encoder_list): ModuleList(
            (0): DSVT_EncoderLayer(
              (win_attn): SetAttention(
                (self_attn): MultiheadAttention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)
                )
                (linear1): Linear(in_features=192, out_features=384, bias=True)
                (dropout): Dropout(p=0, inplace=False)
                (linear2): Linear(in_features=384, out_features=192, bias=True)
                (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (dropout1): Identity()
                (dropout2): Identity()
              )
              (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            )
            (1): DSVT_EncoderLayer(
              (win_attn): SetAttention(
                (self_attn): MultiheadAttention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)
                )
                (linear1): Linear(in_features=192, out_features=384, bias=True)
                (dropout): Dropout(p=0, inplace=False)
                (linear2): Linear(in_features=384, out_features=192, bias=True)
                (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (dropout1): Identity()
                (dropout2): Identity()
              )
              (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (residual_norm_stage_0): ModuleList(
        (0): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
      )
      (stage_0_reduction): Stage_ReductionAtt_Block(
        (query_func): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)
        (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)
        )
      )
      (stage_1): ModuleList(
        (0): DSVTBlock(
          (encoder_list): ModuleList(
            (0): DSVT_EncoderLayer(
              (win_attn): SetAttention(
                (self_attn): MultiheadAttention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)
                )
                (linear1): Linear(in_features=192, out_features=384, bias=True)
                (dropout): Dropout(p=0, inplace=False)
                (linear2): Linear(in_features=384, out_features=192, bias=True)
                (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (dropout1): Identity()
                (dropout2): Identity()
              )
              (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            )
            (1): DSVT_EncoderLayer(
              (win_attn): SetAttention(
                (self_attn): MultiheadAttention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)
                )
                (linear1): Linear(in_features=192, out_features=384, bias=True)
                (dropout): Dropout(p=0, inplace=False)
                (linear2): Linear(in_features=384, out_features=192, bias=True)
                (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (dropout1): Identity()
                (dropout2): Identity()
              )
              (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (residual_norm_stage_1): ModuleList(
        (0): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
      )
      (stage_1_reduction): Stage_ReductionAtt_Block(
        (query_func): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)
        (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)
        )
      )
      (stage_2): ModuleList(
        (0): DSVTBlock(
          (encoder_list): ModuleList(
            (0): DSVT_EncoderLayer(
              (win_attn): SetAttention(
                (self_attn): MultiheadAttention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)
                )
                (linear1): Linear(in_features=192, out_features=384, bias=True)
                (dropout): Dropout(p=0, inplace=False)
                (linear2): Linear(in_features=384, out_features=192, bias=True)
                (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (dropout1): Identity()
                (dropout2): Identity()
              )
              (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            )
            (1): DSVT_EncoderLayer(
              (win_attn): SetAttention(
                (self_attn): MultiheadAttention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)
                )
                (linear1): Linear(in_features=192, out_features=384, bias=True)
                (dropout): Dropout(p=0, inplace=False)
                (linear2): Linear(in_features=384, out_features=192, bias=True)
                (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (dropout1): Identity()
                (dropout2): Identity()
              )
              (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (residual_norm_stage_2): ModuleList(
        (0): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
      )
      (stage_2_reduction): Stage_ReductionAtt_Block(
        (query_func): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)
        )
      )
      (stage_3): ModuleList(
        (0): DSVTBlock(
          (encoder_list): ModuleList(
            (0): DSVT_EncoderLayer(
              (win_attn): SetAttention(
                (self_attn): MultiheadAttention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)
                )
                (linear1): Linear(in_features=192, out_features=384, bias=True)
                (dropout): Dropout(p=0, inplace=False)
                (linear2): Linear(in_features=384, out_features=192, bias=True)
                (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (dropout1): Identity()
                (dropout2): Identity()
              )
              (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            )
            (1): DSVT_EncoderLayer(
              (win_attn): SetAttention(
                (self_attn): MultiheadAttention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)
                )
                (linear1): Linear(in_features=192, out_features=384, bias=True)
                (dropout): Dropout(p=0, inplace=False)
                (linear2): Linear(in_features=384, out_features=192, bias=True)
                (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (dropout1): Identity()
                (dropout2): Identity()
              )
              (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (residual_norm_stage_3): ModuleList(
        (0): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
      )
    )
    (map_to_bev_module): PointPillarScatter3d()
    (pfe): None
    (backbone_2d): BaseBEVResBackbone(
      (blocks): ModuleList(
        (0): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (relu1): ReLU()
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (relu2): ReLU()
            (downsample_layer): Sequential(
              (0): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            )
          )
          (1): BasicBlock(
            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (relu1): ReLU()
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (relu2): ReLU()
          )
        )
        (1): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (relu1): ReLU()
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (relu2): ReLU()
            (downsample_layer): Sequential(
              (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
              (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            )
          )
          (1): BasicBlock(
            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (relu1): ReLU()
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (relu2): ReLU()
          )
          (2): BasicBlock(
            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (relu1): ReLU()
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (relu2): ReLU()
          )
        )
        (2): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (relu1): ReLU()
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (relu2): ReLU()
            (downsample_layer): Sequential(
              (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
              (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            )
          )
          (1): BasicBlock(
            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (relu1): ReLU()
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (relu2): ReLU()
          )
          (2): BasicBlock(
            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (relu1): ReLU()
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (relu2): ReLU()
          )
        )
      )
      (deblocks): ModuleList(
        (0): Sequential(
          (0): ConvTranspose2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU()
        )
        (1): Sequential(
          (0): ConvTranspose2d(128, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)
          (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU()
        )
        (2): Sequential(
          (0): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(4, 4), bias=False)
          (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU()
        )
      )
    )
    (dense_head): CenterHead(
      (shared_conv): Sequential(
        (0): Conv2d(384, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU()
      )
      (heads_list): ModuleList(
        (0): SeparateHead(
          (center): Sequential(
            (0): Sequential(
              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (2): ReLU()
            )
            (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (center_z): Sequential(
            (0): Sequential(
              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (2): ReLU()
            )
            (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (dim): Sequential(
            (0): Sequential(
              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (2): ReLU()
            )
            (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (rot): Sequential(
            (0): Sequential(
              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (2): ReLU()
            )
            (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (iou): Sequential(
            (0): Sequential(
              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (2): ReLU()
            )
            (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (hm): Sequential(
            (0): Sequential(
              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (2): ReLU()
            )
            (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
        )
      )
      (hm_loss_func): FocalLossCenterNet()
      (reg_loss_func): RegLossCenterNet()
    )
    (point_head): None
    (roi_head): None
  )
)
2024-10-16 22:19:35,335   INFO  **********************Start training waymo_models/dsvt_voxel_whole(default)**********************
2024-10-16 22:20:15,676   INFO  Train:    1/30 (  3%) [   0/3435 (  0%)]  Loss: 73.97 (74.0)  LR: 3.000e-05  Time cost: 00:08/7:59:08 [00:40/239:34:01]  Acc_iter 1           Data time: 7.30(7.30)  Forward time: 1.11(1.11)  Batch time: 8.40(8.40)
2024-10-16 22:22:46,052   INFO  Train:    1/30 (  3%) [  49/3435 (  1%)]  Loss: 23.61 (38.5)  LR: 3.017e-05  Time cost: 02:38/2:59:10 [03:10/90:50:18]  Acc_iter 50          Data time: 0.00(1.16)  Forward time: 1.06(2.01)  Batch time: 1.06(3.18)
2024-10-16 22:24:48,449   INFO  Train:    1/30 (  3%) [  99/3435 (  3%)]  Loss: 15.94 (29.2)  LR: 3.068e-05  Time cost: 04:41/2:36:18 [05:13/80:23:59]  Acc_iter 100         Data time: 0.00(0.94)  Forward time: 0.99(1.87)  Batch time: 0.99(2.81)
2024-10-16 22:25:11,320   INFO  Save latest model to /home/ailab/git/Team_3/baseline_code_and_model/03_3D객체검출차량용/02_baseline_code_and_model/output/waymo_models/dsvt_voxel_whole/default/ckpt/latest_model
2024-10-16 22:27:19,654   INFO  Train:    1/30 (  3%) [ 149/3435 (  4%)]  Loss: 13.84 (24.3)  LR: 3.153e-05  Time cost: 07:12/2:37:51 [07:44/82:23:13]  Acc_iter 150         Data time: 0.00(1.01)  Forward time: 1.02(1.87)  Batch time: 1.02(2.88)
2024-10-16 22:27:19,941   INFO  3090-1                      Wed Oct 16 22:27:19 2024  470.223.02
[0] NVIDIA GeForce RTX 3090 | 33'C,   0 % |    10 / 24268 MB | gdm(4M) ailab(4M)
[1] NVIDIA GeForce RTX 3090 | 32'C,   0 % |    10 / 24268 MB | gdm(4M) ailab(4M)
[2] NVIDIA GeForce RTX 3090 | 47'C,   6 % | 24164 / 24268 MB | ailab(24151M) gdm(4M) ailab(4M)
[3] NVIDIA GeForce RTX 3090 | 40'C,  82 % | 24003 / 24260 MB | ailab(23739M) gdm(26M) gdm(73M) ailab(94M) ailab(63M)

2024-10-16 22:29:22,253   INFO  Train:    1/30 (  3%) [ 199/3435 (  6%)]  Loss: 11.94 (21.4)  LR: 3.273e-05  Time cost: 09:14/2:29:39 [09:46/79:16:24]  Acc_iter 200         Data time: 0.00(0.94)  Forward time: 1.13(1.84)  Batch time: 1.13(2.77)
2024-10-16 22:30:13,054   INFO  Save latest model to /home/ailab/git/Team_3/baseline_code_and_model/03_3D객체검출차량용/02_baseline_code_and_model/output/waymo_models/dsvt_voxel_whole/default/ckpt/latest_model
2024-10-16 22:31:06,253   INFO  Train:    1/30 (  3%) [ 249/3435 (  7%)]  Loss: 11.56 (19.5)  LR: 3.428e-05  Time cost: 10:58/2:19:57 [11:30/75:16:01]  Acc_iter 250         Data time: 0.00(0.86)  Forward time: 1.04(1.78)  Batch time: 1.04(2.64)
2024-10-16 22:32:49,194   INFO  Train:    1/30 (  3%) [ 299/3435 (  9%)]  Loss: 10.79 (18.2)  LR: 3.617e-05  Time cost: 12:41/2:12:44 [13:13/72:29:09]  Acc_iter 300         Data time: 0.00(0.81)  Forward time: 1.04(1.73)  Batch time: 1.05(2.54)
2024-10-16 22:32:49,506   INFO  3090-1                      Wed Oct 16 22:32:49 2024  470.223.02
[0] NVIDIA GeForce RTX 3090 | 34'C,   0 % |    10 / 24268 MB | gdm(4M) ailab(4M)
[1] NVIDIA GeForce RTX 3090 | 34'C,   0 % |    10 / 24268 MB | gdm(4M) ailab(4M)
[2] NVIDIA GeForce RTX 3090 | 49'C,  26 % | 24164 / 24268 MB | ailab(24151M) gdm(4M) ailab(4M)
[3] NVIDIA GeForce RTX 3090 | 42'C, 100 % | 24129 / 24260 MB | ailab(23865M) gdm(26M) gdm(73M) ailab(94M) ailab(63M)

2024-10-16 22:34:22,612   INFO  Train:    1/30 (  3%) [ 349/3435 ( 10%)]  Loss: 10.57 (17.2)  LR: 3.840e-05  Time cost: 14:15/2:05:41 [14:47/69:42:53]  Acc_iter 350         Data time: 0.00(0.76)  Forward time: 1.06(1.69)  Batch time: 1.07(2.44)
2024-10-16 22:35:08,158   INFO  Save latest model to /home/ailab/git/Team_3/baseline_code_and_model/03_3D객체검출차량용/02_baseline_code_and_model/output/waymo_models/dsvt_voxel_whole/default/ckpt/latest_model
2024-10-16 22:35:44,432   INFO  Train:    1/30 (  3%) [ 399/3435 ( 12%)]  Loss: 10.05 (16.4)  LR: 4.097e-05  Time cost: 15:37/1:58:32 [16:09/66:48:12]  Acc_iter 400         Data time: 0.00(0.70)  Forward time: 0.96(1.64)  Batch time: 0.97(2.34)
2024-10-16 22:37:20,619   INFO  Train:    1/30 (  3%) [ 449/3435 ( 13%)]  Loss: 10.87 (15.7)  LR: 4.389e-05  Time cost: 17:13/1:54:16 [17:45/65:26:37]  Acc_iter 450         Data time: 0.00(0.68)  Forward time: 0.95(1.62)  Batch time: 0.96(2.30)
2024-10-16 22:37:20,901   INFO  3090-1                      Wed Oct 16 22:37:20 2024  470.223.02
[0] NVIDIA GeForce RTX 3090 | 36'C,   0 % |    10 / 24268 MB | gdm(4M) ailab(4M)
[1] NVIDIA GeForce RTX 3090 | 35'C,   0 % |    10 / 24268 MB | gdm(4M) ailab(4M)
[2] NVIDIA GeForce RTX 3090 | 51'C,   0 % | 24164 / 24268 MB | ailab(24151M) gdm(4M) ailab(4M)
[3] NVIDIA GeForce RTX 3090 | 42'C,  95 % | 24131 / 24260 MB | ailab(23867M) gdm(26M) gdm(73M) ailab(94M) ailab(63M)

